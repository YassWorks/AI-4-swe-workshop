{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8316e66",
   "metadata": {},
   "source": [
    "## 1. Setting up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e879575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_cerebras import ChatCerebras\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "print(\"Environment and imports ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2b5e55",
   "metadata": {},
   "source": [
    "### Essential imports for LangChain applications\n",
    "- `dotenv`: Load environment variables from .env file  \n",
    "- `ChatCerebras`: The LLM model we'll use\n",
    "- `ChatPromptTemplate`: For creating structured prompts\n",
    "- `tool`: Decorator for creating custom tools\n",
    "- `create_react_agent`: For building AI agents that can use tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2119f667",
   "metadata": {},
   "source": [
    "## 2. Setting Up the ChatCerebras Model\n",
    "\n",
    "LangChain supports various LLM providers. Here we'll use ChatCerebras, which requires an API key stored in your `.env` file as `CEREBRAS_API_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36304b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"qwen-3-32b\"\n",
    "api_key = os.getenv(\"CEREBRAS_API_KEY\")\n",
    "\n",
    "llm = ChatCerebras(\n",
    "    model=model_name,\n",
    "    api_key=api_key,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(f\"ChatCerebras model '{model_name}' initialized!\")\n",
    "print(f\"API key loaded: {'Yes' if api_key else 'Missing CEREBRAS_API_KEY'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1e0e73",
   "metadata": {},
   "source": [
    "### Initialize the ChatCerebras model\n",
    "- `temperature=0`: Makes responses deterministic (same input = same output)\n",
    "- API key must be stored in `.env` file as `CEREBRAS_API_KEY`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9f176e",
   "metadata": {},
   "source": [
    "## 3. Basic Chat with Prompt Templates\n",
    "\n",
    "Let's start with a simple chat interaction using `ChatPromptTemplate`. This is perfect for straightforward question-answering scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22daa5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful coding assistant. Provide clear, concise answers.\"),\n",
    "    (\"human\", \"{prompt}\"),\n",
    "])\n",
    "\n",
    "# Example of few-shot prompting\n",
    "template2 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful coding assistant. Provide clear, concise answers.\"),\n",
    "    (\"human\", \"What's the weather like today in France?\"),\n",
    "    (\"assistant\", \"The weather in France today is sunny with a high of 25Â°C.\"),\n",
    "    (\"human\", \"{prompt}\"),\n",
    "])\n",
    "\n",
    "llm_chain = template | llm\n",
    "\n",
    "user_question = \"What is the difference between a list and a tuple in Python?\"\n",
    "response = llm_chain.invoke({\"prompt\": user_question})\n",
    "\n",
    "print(\"AI Response:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b44f47",
   "metadata": {},
   "source": [
    "### Create a basic chat chain\n",
    "- Template defines the conversation structure (system + human messages)\n",
    "- Chain combines template with the LLM using the `|` operator\n",
    "- `invoke()` runs the chain with input variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9106c12",
   "metadata": {},
   "source": [
    "## 4. Working with External Prompt Files\n",
    "\n",
    "In real projects, it's better to store prompts in external files. Let's demonstrate how to load prompts from files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56804a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In real projects, you would load system prompts from files\n",
    "\n",
    "system_prompt = \"\"\"You are an expert software engineer.\n",
    "Your job is to help analyze code and provide technical assistance.\n",
    "Always be precise and helpful in your responses.\n",
    "\"\"\"\n",
    "        \n",
    "instructions = \"Please analyze the following code for potential improvements.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7f0dbd",
   "metadata": {},
   "source": [
    "### Loading prompts from external files\n",
    "- Better practice: store prompts in separate `.md` files for easier editing\n",
    "- Both solution files use this pattern for maintainable prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5412619a",
   "metadata": {},
   "source": [
    "## 5. Creating Custom Tools\n",
    "\n",
    "Tools are the building blocks of AI agents. They allow the AI to interact with the external world. Let's create some custom tools using the `@tool` decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746366fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def read_file_tool(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Read the contents of a file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the file to read.\n",
    "\n",
    "    Returns:\n",
    "        str: The contents of the file, or an error message if the file could not be read.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except Exception as e:\n",
    "        return f\"Error reading file: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def write_file_tool(file_path: str, content: str) -> str:\n",
    "    \"\"\"\n",
    "    Write content to a file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the file to write.\n",
    "        content (str): The content to write to the file.\n",
    "\n",
    "    Returns:\n",
    "        str: A message indicating success or failure.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(content)\n",
    "        return f\"File '{file_path}' written successfully.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error writing file: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def create_directory_tool(directory_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Create a new directory.\n",
    "\n",
    "    Args:\n",
    "        directory_path (str): The path to the directory to create.\n",
    "\n",
    "    Returns:\n",
    "        str: A message indicating success or failure.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs(directory_path, exist_ok=True)\n",
    "        return f\"Directory '{directory_path}' created successfully.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error creating directory: {str(e)}\"\n",
    "\n",
    "ALL_TOOLS = [read_file_tool, write_file_tool, create_directory_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba248d95",
   "metadata": {},
   "source": [
    "### Creating custom tools with @tool decorator\n",
    "- Tools allow AI agents to interact with the external world\n",
    "- Each tool needs a docstring that describes what it does\n",
    "- The `ALL_TOOLS` list is used by the agent to access all available tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1752ce3c",
   "metadata": {},
   "source": [
    "## 6. Building AI Agents with LangGraph\n",
    "\n",
    "Now for the exciting part! LangGraph allows us to create AI agents that can use tools to solve complex tasks. We'll use `create_react_agent` to build a ReAct (Reasoning and Acting) agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f15463",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_system_prompt = \"\"\"\n",
    "## Role\n",
    "You are an expert software engineer.\n",
    "Your job is to help analyze code and provide technical assistance.\n",
    "\n",
    "## Style\n",
    "Always be precise and helpful in your responses.\n",
    "\n",
    "## Constraints\n",
    "- Use the provided tools to read/write files and create directories as needed.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=ALL_TOOLS,\n",
    "    prompt=system_prompt\n",
    ")\n",
    "\n",
    "\n",
    "print(\"AI Agent created successfully!\")\n",
    "print(f\"Agent has access to {len(ALL_TOOLS)} tools\")\n",
    "print(\"Agent is ready to receive instructions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dce026",
   "metadata": {},
   "source": [
    "### Building AI agents with LangGraph\n",
    "- `create_react_agent` builds a ReAct (Reasoning and Acting) agent\n",
    "- Agent can use tools to complete complex tasks step by step\n",
    "- System prompt guides the agent's behavior"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
